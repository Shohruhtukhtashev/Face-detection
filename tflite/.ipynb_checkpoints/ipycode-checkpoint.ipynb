{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd7348-04bc-4ab0-87d7-a010bd22d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('humans.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad71b913-f5cb-447f-b9a6-f31aa3dc63dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boxes_scores [592, 537, 239, 263, 0.0] <class 'list'>\n",
      "boxes_scores [592, 549, 248, 235, 0.0] <class 'list'>\n",
      "boxes_scores [591, 555, 246, 224, 0.0] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "def BoxScore(output_data,dwdh,ratio):\n",
    "    boxes,scores = [],[]\n",
    "    for i, (x0, y0, x1, y1, oscore) in enumerate(output_data):\n",
    "        #print('x0',x0.shape)\n",
    "        for j in range(len(x0)):\n",
    "            if oscore[j] >= 0.:\n",
    "                \n",
    "                box = np.array([x0[j]-dwdh[0], y0[j]-dwdh[1], x1[j]-dwdh[0], y1[j]-dwdh[1]])/ratio\n",
    "                #print('box',box)\n",
    "                box = box.round().astype(np.int32).tolist()\n",
    "                score = round(float(oscore[j]), 3)\n",
    "                #print('box_list',box,'score',score)\n",
    "                \n",
    "                if box not in boxes:\n",
    "                    boxes.append(box)\n",
    "                    scores.append(score)\n",
    "    #return boxes, scores\n",
    "    for i,k in zip(boxes,scores):\n",
    "        i.append(k)\n",
    "    return i\n",
    "\n",
    "# def decrease_box(output_data):\n",
    "#     matrix = output_data[output_data[4]>0.1]\n",
    "#     sorted_matrix = matrix[matrix[0].argsort()]\n",
    "#     s = 0\n",
    "#     all = np.array([])\n",
    "#     k = 0\n",
    "#     for i in range(sorted_matrix.shape[0]-1):\n",
    "#         k+=1\n",
    "#         s+=sorted_matrix[i]\n",
    "#         if (sorted_matrix[0][i]//10) == (sorted_matrix[0][i+1]//10):\n",
    "#             pass\n",
    "#         else:\n",
    "#             all = np.append(all,s/k)\n",
    "#             k=0\n",
    "#             s=0\n",
    "#     #all = np.append(all,sorted_matrix[-1])\n",
    "#     return all.reshape(int(all.shape[0]/5),5)\n",
    "# ----     -----\n",
    "def ImageBox(image, new_shape=(640, 640), color=(255, 0, 0)):\n",
    "    \n",
    "    width, height, channel = image.shape\n",
    "    \n",
    "    ratio = min(new_shape[0] / width, new_shape[1] / height)\n",
    "    #print('ratio',ratio)\n",
    "    new_unpad = int(round(height * ratio)), int(round(width * ratio))\n",
    "    #print(new_unpad)\n",
    "    dw, dh = (new_shape[0] - new_unpad[0])/2, (new_shape[1] - new_unpad[1])/2\n",
    "    #print('dw',dw,'dh',dh) 18.0, 0.0\n",
    "    if (height, width) != new_unpad:\n",
    "        image = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    \n",
    "    image = cv2.copyMakeBorder(image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    return image, ratio, (dw, dh)\n",
    "\n",
    "\n",
    "model_path = \"best_float32.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while video.isOpened():\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    image,ratio,dwdh = ImageBox(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.ascontiguousarray(image)\n",
    "    input_data = image.astype(np.float32)/255\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    \n",
    "    boxes_scores = BoxScore(output_data, dwdh, ratio)\n",
    "\n",
    "    def decrease_box(output_data):\n",
    "        matrix = output_data[output_data[:,4]>0.1]\n",
    "        sorted_matrix_x = matrix[matrix[:, 1].argsort()]\n",
    "        sorted_matrix_x = sorted_matrix_x[sorted_matrix_x[:, 0].argsort()]\n",
    "        return sorted_matrix_x\n",
    "\n",
    "    thresh = 0.3\n",
    "    dec_box = decrease_box(boxes_scores)\n",
    "    \n",
    "    # print(len(boxes))\n",
    "    print('boxes_scores',boxes_scores,type(boxes_scores))\n",
    "    # boxes_dect = decrease_box(boxes_scores)\n",
    "\n",
    "    # for box,score in zip(boxes_dect[:,:4],boxes_dect[:,4]):\n",
    "    for (x0,y0,x1,y1,scores) in dec_box[dec_box.shape[0]%10::10]:\n",
    "        for (x0, y0, x1, y1, scores) in dec_box[dec_box.shape[0]%10::10]:            \n",
    "            if scores > thresh:\n",
    "                ymin = int(max(0,x0))\n",
    "                xmin = int(max(0,y0))\n",
    "                ymax = int(min(x1,height))\n",
    "                xmax = int(min(y1,width))\n",
    "        cv2.rectangle(frame, (xmin+150,ymin+80), (xmax+120,ymax), (0,255,0), 2)     \n",
    "    #cv2.imwrite(\"/content/drive/MyDrive/Colab_Notebooks/Yolo_face_detection/result\"+str(i)+\".jpg\",frame)\n",
    "    cv2.imshow(\"input\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "video.release()\n",
    "cv2.destroyAllWindows()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929b1b2-283b-4e6a-a309-dd05f48880e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879cc0f-e8bf-44b2-8c97-293eb9fccdb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c164b58-d517-43e4-92ce-772ad01903be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba13369-6b0a-47c2-8155-41854baae2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5770f52-2cc8-49e8-afff-aa5637c29521",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd381a43-677e-4203-8097-0e535870764f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8cb31-131e-4767-ae8e-12f8c3520ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
